# Vosk Spracherkennung - Verbesserungen

Diese Dokumentation erkl√§rt, wie du die Erkennungsqualit√§t des Vosk-Sprachmodells verbessern kannst.

---

## Problem: Viele Erkennungsfehler

Wenn Vosk viele Fehler macht, gibt es mehrere Verbesserungsm√∂glichkeiten:

---

## 1. Gr√∂√üeres/besseres Modell verwenden

### Aktuelles Modell pr√ºfen

```bash
ls -lh models/
```

### Empfohlene Modelle (von klein zu gro√ü)

| Modell | Gr√∂√üe | Genauigkeit | Geschwindigkeit | Empfehlung |
|--------|-------|-------------|-----------------|------------|
| **vosk-model-de-0.22** | ~45 MB | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | Gut f√ºr Tests |
| **vosk-model-de-0.6-900k** | ~1.8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | ‚úÖ **Beste Genauigkeit** |
| **vosk-model-de-0.6** | ~1.8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | Alternative |

### Gr√∂√üeres Modell installieren

```bash
cd models
# Altes Modell l√∂schen (optional)
# rm -rf vosk-model-de-0.22

# Neues Modell herunterladen
wget https://alphacephei.com/vosk/models/vosk-model-de-0.6-900k.zip
unzip vosk-model-de-0.6-900k.zip

# In .env aktualisieren
VOSK_MODEL_PATH=models/vosk-model-de-0.6-900k
```

**Hinweis:** Das gr√∂√üere Modell ben√∂tigt mehr RAM und ist langsamer, aber deutlich genauer!

---

## 2. Audio-Vorverarbeitung

Die Implementierung enth√§lt jetzt automatische Audio-Vorverarbeitung:

- ‚úÖ **Normalisierung:** Audio wird auf optimalen Pegel gebracht
- ‚úÖ **High-Pass Filter:** Entfernt tiefe Frequenzen/Rauschen
- ‚úÖ **Voice Activity Detection:** √úberspringt leise/leere Chunks

### Aktivieren/Deaktivieren

In `src/speech_recognition_vosk.py`:

```python
recognizer = LiveVoskRecognition(
    model_path=model_path,
    device=settings.audio_input_device,
    enable_audio_processing=True  # True = aktiviert
)
```

---

## 3. Chunk-Dauer optimieren

L√§ngere Chunks = besserer Kontext = bessere Erkennung, aber langsamer.

### Standard-Einstellung

```python
chunk_duration = 2.0  # Sekunden
```

### Empfohlene Werte

- **Kurz (schnell, weniger genau):** `1.5` Sekunden
- **Standard (ausgewogen):** `2.0-3.0` Sekunden ‚úÖ
- **Lang (langsam, sehr genau):** `4.0-5.0` Sekunden

### Anpassen

In `src/speech_recognition_vosk.py` oder beim Aufruf:

```python
recognizer = LiveVoskRecognition(
    model_path=model_path,
    device=settings.audio_input_device,
    chunk_duration=3.0  # L√§ngere Chunks = bessere Erkennung
)
```

---

## 4. Mikrofon-Qualit√§t

### Mikrofon pr√ºfen

```bash
# Audio-Ger√§te auflisten
python -m src.audio_test --list

# Mikrofon-Test mit Pegelanzeige
python -m src.audio_test --mic --device 2
```

### Empfehlungen

- ‚úÖ **Gute Position:** 20-30 cm vom Mund entfernt
- ‚úÖ **Ruhige Umgebung:** Reduziere Hintergrundger√§usche
- ‚úÖ **Richtung:** Sprich direkt ins Mikrofon
- ‚úÖ **Lautst√§rke:** Sprich klar und deutlich (nicht zu leise/laut)

---

## 5. Sample Rate pr√ºfen

Vosk ben√∂tigt **16 kHz** Sample Rate. Die Implementierung setzt dies automatisch, aber pr√ºfe:

```bash
# Pr√ºfe Mikrofon-Sample-Rate
python -m src.audio_test --list
# Sollte 16000 Hz oder h√∂her zeigen
```

---

## 6. Audio-Gain anpassen

### System-Lautst√§rke

```bash
# ALSA Mixer √∂ffnen
alsamixer

# Oder per Kommando
amixer set Capture 80%  # 0-100%
```

### In Python (optional)

Du kannst die Audio-Gain in `_record_chunk()` anpassen:

```python
# Nach Aufnahme, vor Verarbeitung:
audio_data = audio_data * 1.2  # 20% lauter
audio_data = np.clip(audio_data, -32768, 32767)  # Verhindere Clipping
```

---

## 7. Umgebungsbedingungen

### Optimale Bedingungen

- ‚úÖ **Ruhige Umgebung:** Reduziere Hintergrundger√§usche
- ‚úÖ **Gute Akustik:** Vermeide Hall/Echo
- ‚úÖ **Stabile Position:** Mikrofon nicht bewegen w√§hrend Aufnahme
- ‚úÖ **Klare Aussprache:** Sprich deutlich und nicht zu schnell

### Schlechte Bedingungen vermeiden

- ‚ùå Hintergrundmusik
- ‚ùå Mehrere Personen gleichzeitig
- ‚ùå Echo/Hall (z. B. in gro√üen R√§umen)
- ‚ùå Wind/Luftger√§usche
- ‚ùå Zu weit vom Mikrofon entfernt

---

## 8. Vergleich: Modell-Gr√∂√üen

### Test mit beiden Modellen

```bash
# Kleines Modell
VOSK_MODEL_PATH=models/vosk-model-de-0.22 python -m src.main --live-recognition --vosk

# Gro√ües Modell
VOSK_MODEL_PATH=models/vosk-model-de-0.6-900k python -m src.main --live-recognition --vosk
```

**Erwartete Verbesserung:** Das gro√üe Modell sollte **30-50% weniger Fehler** machen.

---

## 9. Debugging: Was wird erkannt?

### Verbose-Modus aktivieren

In `src/speech_recognition_vosk.py`, Zeile 37:

```python
SetLogLevel(0)  # Statt -1 f√ºr mehr Ausgaben
```

### Audio-Dateien speichern (optional)

F√ºge hinzu in `_process_chunk()`:

```python
# Speichere Audio f√ºr Analyse
import soundfile as sf
sf.write(f"debug_audio_{int(time.time())}.wav", audio_data, self.samplerate)
```

Dann kannst du die Dateien analysieren und pr√ºfen, ob die Audio-Qualit√§t gut ist.

---

## 10. Alternative: Whisper lokal

Falls Vosk trotz aller Optimierungen nicht zufriedenstellend ist, kannst du **Whisper lokal** verwenden:

```bash
pip install openai-whisper
```

Whisper ist genauer als Vosk, aber:
- ‚ö†Ô∏è Ben√∂tigt mehr RAM (ca. 2-4 GB)
- ‚ö†Ô∏è Langsamer als Vosk
- ‚úÖ Deutlich bessere Genauigkeit

---

## Zusammenfassung: Schnelle Verbesserungen

1. **Gr√∂√üeres Modell verwenden** (vosk-model-de-0.6-900k)
2. **Chunk-Dauer erh√∂hen** (3.0-4.0 Sekunden)
3. **Audio-Vorverarbeitung aktivieren** (bereits implementiert)
4. **Mikrofon-Position optimieren** (20-30 cm, direkt)
5. **Ruhige Umgebung** (Hintergrundger√§usche reduzieren)

**Erwartete Verbesserung:** 50-70% weniger Fehler bei optimalen Einstellungen.

---

## Troubleshooting

### Problem: Immer noch viele Fehler

**L√∂sung:**
1. Pr√ºfe Mikrofon-Qualit√§t: `python -m src.audio_test --mic`
2. Teste mit gr√∂√üerem Modell
3. Erh√∂he Chunk-Dauer auf 4.0 Sekunden
4. Pr√ºfe Audio-Gain (nicht zu leise/laut)

### Problem: Zu langsam

**L√∂sung:**
1. Verwende kleineres Modell (vosk-model-de-0.22)
2. Reduziere Chunk-Dauer auf 1.5 Sekunden
3. Deaktiviere Audio-Vorverarbeitung (falls scipy fehlt)

### Problem: Keine Erkennung

**L√∂sung:**
1. Pr√ºfe Mikrofon-Anschluss
2. Pr√ºfe Audio-Ger√§t: `python -m src.audio_test --list`
3. Erh√∂he VAD-Threshold in `_detect_speech()`
4. Pr√ºfe Sample Rate (muss 16000 Hz sein)

---

**Viel Erfolg bei der Optimierung!** üé§üîä
