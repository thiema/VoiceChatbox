# Mehrsprachige Spracherkennung (Deutsch + Englisch)

Diese Anleitung erkl√§rt, wie du mehrere Sprachmodelle kombinierst, um sowohl deutsche als auch englische W√∂rter zu erkennen.

---

## √úbersicht

Die mehrsprachige Spracherkennung erm√∂glicht es, **mehrere Vosk-Modelle parallel** zu verwenden:

- ‚úÖ **Deutsch + Englisch** gleichzeitig
- ‚úÖ **Automatische Spracherkennung** (w√§hlt bestes Ergebnis)
- ‚úÖ **Kombinierte Erkennung** (beide Sprachen zusammen)
- ‚úÖ **Code-Switching** (gemischte Sprache: "Hallo, how are you?")

---

## 1. Sprachmodelle herunterladen

### Deutsch (falls noch nicht vorhanden)

```bash
cd models
wget https://alphacephei.com/vosk/models/vosk-model-de-0.22.zip
unzip vosk-model-de-0.22.zip
```

### Englisch

```bash
cd models
wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip
unzip vosk-model-en-us-0.22.zip
```

**Alternative englische Modelle:**
- `vosk-model-en-us-0.22` (~45 MB) - Klein, schnell
- `vosk-model-en-us-0.6` (~1.8 GB) - Gro√ü, sehr genau

---

## 2. Konfiguration

### .env Datei anpassen

```bash
nano .env
```

F√ºge hinzu:

```bash
# Vosk Sprachmodelle
VOSK_MODEL_PATH=models/vosk-model-de-0.22
VOSK_MODEL_PATH_EN=models/vosk-model-en-us-0.22

# Mehrsprachige Erkennung aktivieren
USE_MULTILANG=false  # true = mehrsprachig, false = nur Deutsch
```

---

## 3. Verwendung

### Modus 1: Bestes Ergebnis (empfohlen)

W√§hlt automatisch das beste Ergebnis aus allen Sprachen:

```bash
python -m src.main --live-recognition --vosk --multilang
```

**Funktionsweise:**
- Beide Modelle (DE + EN) transkribieren parallel
- Das Ergebnis mit dem l√§ngsten Text wird gew√§hlt
- Automatische Spracherkennung

**Beispiel:**
```
Sprich: "Hallo, how are you?"
[DE] "Hallo, wie geht es dir"
[EN] "Hallo, how are you"
‚Üí Gew√§hlt: [EN] "Hallo, how are you" (l√§nger, genauer)
```

### Modus 2: Kombiniert

Kombiniert Ergebnisse aller Sprachen:

```bash
python -m src.main --live-recognition --vosk --multilang --combined
```

**Funktionsweise:**
- Beide Modelle transkribieren
- Ergebnisse werden kombiniert
- N√ºtzlich f√ºr Code-Switching

**Beispiel:**
```
Sprich: "Hallo, how are you?"
[DE] "Hallo, wie geht es dir"
[EN] "Hallo, how are you"
‚Üí Kombiniert: "Hallo, wie geht es dir Hallo, how are you"
```

### Modus 3: Alle anzeigen

Zeigt Ergebnisse aller Sprachen:

```bash
python -m src.main --live-recognition --vosk --multilang --all
```

**Funktionsweise:**
- Alle Ergebnisse werden angezeigt
- Bestes Ergebnis f√ºr Display verwendet

---

## 4. Push-to-Talk mit mehreren Sprachen

```bash
# Bestes Ergebnis
python -m src.main --live-recognition --ptt --vosk --multilang

# Kombiniert
python -m src.main --live-recognition --ptt --vosk --multilang --combined
```

---

## 5. Weitere Sprachen hinzuf√ºgen

### Verf√ºgbare Vosk-Modelle

- **Franz√∂sisch:** `vosk-model-fr-0.22`
- **Spanisch:** `vosk-model-es-0.22`
- **Italienisch:** `vosk-model-it-0.22`
- **Russisch:** `vosk-model-ru-0.22`
- **Chinesisch:** `vosk-model-cn-0.22`
- **Weitere:** https://alphacephei.com/vosk/models

### Beispiel: Deutsch + Englisch + Franz√∂sisch

1. **Modelle herunterladen:**
```bash
cd models
wget https://alphacephei.com/vosk/models/vosk-model-fr-0.22.zip
unzip vosk-model-fr-0.22.zip
```

2. **.env erweitern:**
```bash
VOSK_MODEL_PATH_DE=models/vosk-model-de-0.22
VOSK_MODEL_PATH_EN=models/vosk-model-en-us-0.22
VOSK_MODEL_PATH_FR=models/vosk-model-fr-0.22
```

3. **Code anpassen:**
In `src/speech_recognition_multilang.py`, Funktion `run_multilang_vosk_recognition()`:

```python
# Franz√∂sisch hinzuf√ºgen
fr_path = os.getenv("VOSK_MODEL_PATH_FR", "models/vosk-model-fr-0.22")
if fr_path:
    model_paths["fr"] = fr_path
```

---

## 6. Performance

### RAM-Verbrauch

| Anzahl Modelle | RAM (kleine Modelle) | RAM (gro√üe Modelle) |
|----------------|----------------------|---------------------|
| 1 Modell       | ~100 MB              | ~2 GB               |
| 2 Modelle      | ~200 MB              | ~4 GB               |
| 3 Modelle      | ~300 MB              | ~6 GB               |

**Empfehlung f√ºr Raspberry Pi 5 (8 GB):**
- ‚úÖ 2-3 kleine Modelle (0.22)
- ‚ö†Ô∏è 1-2 gro√üe Modelle (0.6)
- ‚ùå Nicht mehr als 2 gro√üe Modelle

### Geschwindigkeit

- **1 Modell:** 100% (Referenz)
- **2 Modelle:** ~180% (etwas langsamer, da parallel)
- **3 Modelle:** ~250% (deutlich langsamer)

**Tipp:** Verwende kleine Modelle (0.22) f√ºr bessere Performance.

---

## 7. Vergleich: Modi

| Modus | Verwendung | Vorteil | Nachteil |
|-------|------------|---------|----------|
| **best** | Standard | Automatische Spracherkennung | Nur eine Sprache |
| **combined** | Code-Switching | Beide Sprachen | Doppelte W√∂rter m√∂glich |
| **all** | Debugging | Alle Ergebnisse sichtbar | Langsam, viel Output |

**Empfehlung:** `best` f√ºr normale Nutzung, `combined` f√ºr gemischte Sprache.

---

## 8. Beispiel-Szenarien

### Szenario 1: Deutsche und englische W√∂rter

**Eingabe:** "Hallo, how are you? Ich bin gut."

**Modus "best":**
```
[DE] "Hallo, wie geht es dir? Ich bin gut"
[EN] "Hallo, how are you? I am good"
‚Üí Gew√§hlt: [EN] (l√§nger)
```

**Modus "combined":**
```
‚Üí "Hallo, wie geht es dir? Ich bin gut Hallo, how are you? I am good"
```

### Szenario 2: Code-Switching

**Eingabe:** "Das ist ein test"

**Modus "best":**
```
[DE] "Das ist ein Test"
[EN] "That is a test"
‚Üí Gew√§hlt: [DE] (passt besser)
```

---

## 9. Troubleshooting

### Problem: Modell nicht gefunden

**Fehlermeldung:**
```
‚ö†Ô∏è  Warnung: Modell f√ºr en nicht gefunden: models/vosk-model-en-us-0.22
```

**L√∂sung:**
1. Pr√ºfe Modell-Pfad in `.env`
2. Pr√ºfe, ob Modell existiert: `ls -la models/vosk-model-en-us-0.22/`
3. Verwende absoluten Pfad: `VOSK_MODEL_PATH_EN=/home/user/models/vosk-model-en-us-0.22`

### Problem: Zu langsam

**L√∂sung:**
- Verwende kleinere Modelle (0.22 statt 0.6)
- Reduziere Anzahl der Modelle
- Erh√∂he `chunk_duration` (weniger h√§ufige Transkription)

### Problem: Falsche Sprache erkannt

**L√∂sung:**
- Pr√ºfe, ob beide Modelle korrekt geladen wurden
- Verwende Modus `--all` um alle Ergebnisse zu sehen
- Stelle sicher, dass beide Modelle die richtige Sprache haben

---

## 10. Erweiterte Konfiguration

### Nur bestimmte Sprachen verwenden

In Code anpassen:

```python
# Nur Deutsch und Englisch
recognizer = LiveMultiLanguageVoskRecognition(
    model_paths={"de": "models/vosk-model-de-0.22", "en": "models/vosk-model-en-us-0.22"},
    mode="best"
)
```

### Gewichtete Auswahl

Du kannst die Auswahl-Logik in `transcribe_audio_best()` anpassen:

```python
# Statt l√§ngstem Text, verwende Confidence-Score (falls verf√ºgbar)
# Oder bevorzuge bestimmte Sprache
```

---

## Zusammenfassung

**Schnellstart:**
1. Modelle herunterladen (DE + EN)
2. `.env` konfigurieren
3. `python -m src.main --live-recognition --vosk --multilang`

**Vorteile:**
- ‚úÖ Automatische Spracherkennung
- ‚úÖ Unterst√ºtzt Code-Switching
- ‚úÖ Flexibel erweiterbar

**Nachteile:**
- ‚ö†Ô∏è H√∂herer RAM-Verbrauch
- ‚ö†Ô∏è Etwas langsamer

---

**Viel Erfolg mit der mehrsprachigen Erkennung!** üåçüé§
